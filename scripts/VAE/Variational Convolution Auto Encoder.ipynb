{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Convolution Auto Encoder\n",
    "\n",
    "일자 : 2017. 07. 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional.  Tensorflow Graph Visualization ]\n",
    "\n",
    "---\n",
    "\n",
    "> _Jupyter에서 Tensorflow에서 구성되는 Graph를 시각적으로 보여주기 위한 helper 메소드입니다._<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import numpy as np    \n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# \\[ Fashion MNIST \\]\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. 데이터 가져오기\n",
    "\n",
    "* Fashion MNIST 데이터를 가져오도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 다운로드\n",
    "path = \"https://s3.ap-northeast-2.amazonaws.com/pai-datasets/all-about-mnist/fashionmnist/train.csv\"\n",
    "if not os.path.exists(\"fashion_mnist.csv\"):\n",
    "    !wget path -o ./fashion_mnist.csv\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashionmnist/train.csv 가져오기\n",
    "df = pd.read_csv(\"fashion_mnist.csv\")\n",
    "images = df.iloc[:,1:].values.reshape(-1,28,28)\n",
    "labels = df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 읽어보기\n",
    "\n",
    "* MNIST와 같이 총 10가지의 라벨이 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"T-shirt\",'Trouser','Pullover','Dress','Coat',\n",
    "               'Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "n_row = 4\n",
    "n_col = 4\n",
    "\n",
    "for idx, (image, label) in enumerate(zip(images, labels),1):\n",
    "    ax = fig.add_subplot(n_row,n_col,idx)\n",
    "    \n",
    "    ax.set_title(label_names[label])\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])    \n",
    "    if idx >= n_row * n_col:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# \\[ Neural Network Modeling \\]\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "이번 시간에는 `Variational Convolution Auto Encoder`를 모델링하는 시간을 가지도록 하겠습니다. Tensorflow를 이용해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 인코더 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D = partial(tf.layers.Conv2D,\n",
    "                 padding='same',\n",
    "                 activation=tf.nn.leaky_relu)\n",
    "BatchNorm = tf.layers.BatchNormalization\n",
    "MaxPooling2D = partial(tf.layers.MaxPooling2D,\n",
    "                       pool_size=(2,2),\n",
    "                       strides=(2,2))\n",
    "\n",
    "latent_size = 16\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=(None,28,28,1), name='images')\n",
    "    is_train = tf.placeholder_with_default(False, None, name='is_train')\n",
    "    lr = tf.placeholder_with_default(0.01, None, name='learning_rate')\n",
    "    \n",
    "    # Encoder Block 1  \n",
    "    with tf.variable_scope('encoder_block1'):\n",
    "        conv1_1 = Conv2D(8,(3,3),name='conv1_1')(x)\n",
    "        norm1_1 = BatchNorm(name='norm1_1')(conv1_1, training=is_train)\n",
    "        conv1_2 = Conv2D(8,(3,3),name='conv1_2')(norm1_1)\n",
    "        norm1_2 = BatchNorm(name='norm1_2')(conv1_2, training=is_train)\n",
    "        pool1 = MaxPooling2D(name='pool1')(norm1_2)\n",
    "    \n",
    "    # Encoder Block 2\n",
    "    with tf.variable_scope('encoder_block2'):    \n",
    "        conv2_1 = Conv2D(16,(3,3),name='conv2_1')(pool1)\n",
    "        norm2_1 = BatchNorm(name='norm2_1')(conv2_1,training=is_train)\n",
    "        conv2_2 = Conv2D(16,(3,3),name='conv2_2')(norm2_1)\n",
    "        norm2_2 = BatchNorm(name='norm2_2')(conv2_2,training=is_train)\n",
    "        pool2 = MaxPooling2D(name='poo12')(norm2_2)\n",
    "\n",
    "    # Encoder Block 3\n",
    "    with tf.variable_scope('encoder_block3'):    \n",
    "        conv3_1 = Conv2D(32,(3,3),name='conv3_1')(pool2)\n",
    "        norm3_1 = BatchNorm(name='norm3_1')(conv3_1,training=is_train)\n",
    "        conv3_2 = Conv2D(32,(3,3),name='conv3_2')(norm3_1)\n",
    "        norm3_2 = BatchNorm(name='norm3_2')(conv3_2,training=is_train)\n",
    "        pool3 = MaxPooling2D(name='poo13')(norm3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Reparameterization Trick 구현하기\n",
    "\n",
    "우리는 인코더에서 만들어낸 code의 평균과 표준편차에서, 하나의 Code를 랜덤하게 추출하게 됩니다.<br>\n",
    "이렇게 랜덤하게 추출하게 되더라도, 아 잠재 공간 내 이미지들은 유사해야한다는 가정이 있어,<br>\n",
    "Decoder는 원래 이미지로 복원하는 방향으로 학습되게 됩니다.\n",
    "\n",
    "$softplus(x) = np.log(1+np.exp(x))$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.variable_scope('reparameterization_trick'):\n",
    "        flatten = tf.layers.Flatten()(pool3)\n",
    "        code_mean = tf.layers.Dense(latent_size, name='code_mean')(flatten)\n",
    "        code_sigma = tf.layers.Dense(latent_size, \n",
    "                                     activation=tf.nn.softplus,\n",
    "                                     name='code_var')(flatten)\n",
    "        # reparameterization trick\n",
    "        noise = tf.random.normal(tf.shape(code_sigma))\n",
    "        sampled_code = code_mean + code_sigma * noise\n",
    "    sampled_code = tf.identity(sampled_code,\"sampled_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Decoder 구성하기\n",
    "\n",
    "여느 Stacked Auto Encoder와 같이 복원하는 방향으로 학습하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import UpSampling2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2DTranspose = partial(tf.layers.Conv2DTranspose,\n",
    "                          activation=tf.nn.leaky_relu,\n",
    "                          padding='same')\n",
    "\n",
    "with graph.as_default():\n",
    "    # Decoder reshape\n",
    "    _, h_encoded, w_encoded, n_encoded = pool3.shape.as_list()\n",
    "    decoded = tf.layers.Dense(h_encoded*w_encoded*n_encoded,\n",
    "                   activation=tf.nn.leaky_relu,\n",
    "                   name='dense_decoded')(sampled_code)\n",
    "    decoded = tf.reshape(decoded,(-1,h_encoded,w_encoded,n_encoded))\n",
    "\n",
    "    # Decoder Block 3\n",
    "    with tf.variable_scope('decoder_block3'):\n",
    "        upsample3 = UpSampling2D((2,2),name='upsample3')(decoded)\n",
    "        padding = ZeroPadding2D(padding=((0,1),(0,1)),\n",
    "                                name='padding')(upsample3)\n",
    "        deconv3_1 = Conv2DTranspose(32,(3,3),name='deconv3_1')(padding)\n",
    "        denorm3_1 = BatchNorm(name='denorm3_1')(deconv3_1,training=is_train)\n",
    "        deconv3_2 = Conv2DTranspose(32,(3,3),name='deconv3_2')(denorm3_1)\n",
    "        denorm3_2 = BatchNorm(name='denorm3_2')(deconv3_2,training=is_train)\n",
    "\n",
    "    # Decoder Block 2\n",
    "    with tf.variable_scope('decoder_block2'):\n",
    "        upsample2 = UpSampling2D((2,2),name='upsample2')(denorm3_2)\n",
    "        deconv2_1 = Conv2DTranspose(16,(3,3),name='deconv2_1')(upsample2)\n",
    "        denorm2_1 = BatchNorm(name='denorm2_1')(deconv2_1,training=is_train)\n",
    "        deconv2_2 = Conv2DTranspose(16,(3,3),name='deconv2_2')(denorm2_1)\n",
    "        denorm2_2 = BatchNorm(name='denorm2_2')(deconv2_2,training=is_train)\n",
    "\n",
    "    # Decoder Block 1\n",
    "    with tf.variable_scope('decoder_block1'):\n",
    "        upsample1 = UpSampling2D((2,2),name='upsample1')(denorm2_2)\n",
    "        deconv1_1 = Conv2DTranspose(8,(3,3),name='deconv1_1')(upsample1)\n",
    "        outputs = Conv2DTranspose(1,(3,3),activation='sigmoid',\n",
    "                                 name='output')(deconv1_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Loss 구성하기\n",
    "\n",
    "Sparse Autoencoder와 같이, 우리는 랜덤하게 뽑아진 Code의 분포가 정규분포의 형태를 지켰는지에 대해 Regularization 손실을 걸어주게 됩니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-8\n",
    "with graph.as_default():        \n",
    "    with tf.variable_scope(\"losses\"):\n",
    "        reconstruction_loss = -tf.reduce_sum(x * tf.log(epsilon+outputs) + \n",
    "                                    (1-x) * tf.log(epsilon+1-outputs),1)\n",
    "        reconstruction_loss = tf.reduce_mean(reconstruction_loss)\n",
    "        with tf.variable_scope(\"kl_divergence\"):\n",
    "            latent_loss = 0.5 * tf.reduce_sum(\n",
    "                tf.square(code_mean) + tf.square(code_sigma) - \n",
    "                tf.log(epsilon + tf.square(code_sigma)) - 1,1)\n",
    "            latent_loss = tf.reduce_mean(latent_loss)\n",
    "        loss = reconstruction_loss + latent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 학습을 위한 operation 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.variable_scope('metric'):\n",
    "        mse = tf.losses.mean_squared_error(x, outputs)\n",
    "        rmse = tf.sqrt(mse, name='rmse')\n",
    "        \n",
    "    with tf.variable_scope('train'):\n",
    "        train_op = (tf.train\n",
    "                    .AdamOptimizer(lr)\n",
    "                    .minimize(loss, name='train_op'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 100 # epoch 횟수\n",
    "num_batch = 128 # 배치 크기\n",
    "num_data = len(images) # data의 수\n",
    "num_step = num_data // num_batch # 1 epoch 별 학습 횟수\n",
    "\n",
    "with graph.as_default():\n",
    "    sess = tf.Session(graph=graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(num_epoch):        \n",
    "        for j in tqdm(range(num_step)):\n",
    "            batch_images = images[j*num_batch:(j+1)*num_batch,:,:,None].copy()\n",
    "            batch_images = (batch_images/255.)\n",
    "            sess.run(train_op, feed_dict={x:batch_images,\n",
    "                                          lr:0.001})\n",
    "            \n",
    "            rec, lat, tot, rmse_value = sess.run(\n",
    "                [reconstruction_loss,latent_loss, loss, rmse], \n",
    "                feed_dict={x:batch_images})\n",
    "            print(\"{:2d}th epoch 전체 손실 : {:.3f}, 재구성 손실 : {:.3f} 잠재 손실 : {:.3f} RMSE : {:.3f}\"\n",
    "                  .format(i,tot,rec,lat, rmse_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        rec, lat, tot, rmse_value = sess.run(\n",
    "            [reconstruction_loss,latent_loss, loss, rmse], \n",
    "            feed_dict={x:train_images[:,:,:,None]})\n",
    "        print(\"{:2d}th epoch 전체 손실 : {:.3f}, 재구성 손실 : {:.3f} 잠재 손실 : {:.3f} RMSE : {:.3f}\"\n",
    "              .format(i,tot,rec,lat, rmse_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
